# MQAR (Multi-Query Associative Recall) Synthetic Dataset
# For testing state capacity and SSM limitations (Figure 1)
#
# CRITICAL: d_state=64 forces state capacity cliff
# Key/Value ranges prevent token overlap
# Structure: [key1 : val1 key2 : val2 ... QUERY k1 k2 ... EOS]

name: mqar

dataset_type: synthetic
dataset_class: MQARDataset

# Sequence lengths (required by train.py tokenizer setup)
max_src_length: 2048
max_tgt_length: 2048

# Tokenizer settings (MQAR uses its own vocabulary but train.py expects these)
tokenizer_type: custom
tokenizer_path: data/tokenizer/tokenizer.json

# MQAR configuration (forces state capacity cliff)
mqar:
  d_state: 64  # CRITICAL: Forces state to forget
  num_pairs: 64  # Number of key-value pairs
  num_queries: 16  # Queries per sample
  vocab_size: 8192
  seq_length: 512

  # Special tokens
  pad_token_id: 0
  eos_token_id: 2
  kv_sep_token_id: 3  # ':' separator between key and value
  query_token_id: 4   # QUERY marker

  # Token ranges (no overlap!)
  key_token_start: 10
  key_token_end: 4096
  value_token_start: 4096
  value_token_end: 8192

# Curriculum settings for MQAR
curriculum:
  enabled: true
  stages: null  # Use num_pairs_range instead
  num_pairs_range: [16, 32, 64, 128, 256, 512]
  samples_per_stage: 5000

# Collation
collator_mode: mqar

# Data loading - OPTIMIZED FOR 26 CPU CORES
num_workers: 20
prefetch_factor: 8
pin_memory: true
